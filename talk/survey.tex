% Auriga theme
% find the most up-to-date version here: https://github.com/anishathalye/auriga

\documentclass[14pt,aspectratio=169]{beamer}
\usepackage{pgfpages}
\usepackage{fancyvrb}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{booktabs}
\pgfplotsset{compat=1.18}

% Define colors
\definecolor{c1}{HTML}{CB6040}
\definecolor{c2}{HTML}{F2E5BF}
\definecolor{c3}{HTML}{FD8B51}
\definecolor{c4}{HTML}{257180}
% Use natbib with author-year citation style
%\usepackage[authoryear]{natbib}

% Add the bibliography style compatible with author-year
%\bibliographystyle{plainnat}
\definecolor{red}{RGB}{181, 23, 0}
\definecolor{blue}{RGB}{0, 118, 186}
\definecolor{gray}{RGB}{50, 50, 50}

\newcommand{\cx}{\textcolor{c1}{x}}
\newcommand{\cy}{\textcolor{c3}{y}}
\newcommand{\cz}{\textcolor{c4}{z}}

\newcommand{\Ver}{\text{Ver}}

\newcommand{\cfy}[1]{\textcolor{c3}{#1}}
\newcommand{\cfz}[1]{\textcolor{c4}{#1}}
\newcommand{\czT}{\cfz{z_{1:T}}}

\setbeamercolor{palette primary}{fg=c1,bg=white}
\setbeamercolor{palette secondary}{fg=c2,bg=white}
\setbeamercolor{palette tertiary}{bg=c3,fg=white}
\setbeamercolor{palette quaternary}{fg=black,bg=white}
\setbeamercolor{structure}{fg=c1}


\setbeamertemplate{bibliography item}[text]

\renewcommand{\footnote}[1]{
    \begin{tikzpicture}[remember picture,overlay]
        \node[anchor=north east, xshift=-0.2cm, yshift=-0.2cm] at (current page.north east) {\footnotesize #1};
    \end{tikzpicture}
}
\usepackage{tcolorbox}
\usetheme{auriga}
\usecolortheme{auriga}
\setbeamercolor{math text}{fg=gray}

\newcommand\blfootnote[1]{%
\begingroup
\renewcommand\thefootnote{}\footnote{\hfill\parbox[t]{0.5\textwidth}{\raggedleft #1}}%
\addtocounter{footnote}{-1}%
\endgroup
}

%\setbeamertemplate{footline}[]
%\renewcommand\footnotemark{}


% define some colors for a consistent theme across slides
\title{Speculations \\ on \\ Test-Time Scaling}
\author{Sasha Rush \  Daniel Ritter}

\institute[shortinst]{Cornell}
% \institute[shortinst]{\inst{*} Preprint}

\setcounter{tocdepth}{1}
\begin{document}

\frame{\titlepage}


\section{Introduction}

\begin{frame}[t]{}
	%\includegraphics[width=\linewidth]{}
	\note{
		LLM (2018-2024) driven by training scaling
		Speculation: Benefit of static data running out
		o1 - Large-scale RL Training leading to search usage.
	}
\end{frame}


\begin{frame}[t]{}
	\includegraphics[width=\linewidth]{images/compute.png}
\end{frame}

\begin{frame}{Importance of Search}
	\begin{itemize}
		\item
	\end{itemize}
	\blfootnote{}
\end{frame}

\begin{frame}{Bitter Lesson}
	\begin{tcolorbox}[colback=white,colframe=black,boxrule=0.5pt]
		The bitter lesson is based on the historical observations that 1) AI researchers have often tried to build knowledge into their agents,
		2) this always helps in the short term, and is personally satisfying to the researcher, but 3) in the long run it plateaus and even inhibits
		further progress, and 4) breakthrough progress eventually arrives by an opposing approach based on scaling computation by \textbf{search and learning}.
	\end{tcolorbox}

	\blfootnote{}
\end{frame}



\begin{frame}{Example Problem}

	\begin{tcolorbox}[colback=white,colframe=black,boxrule=0.5pt]

	\end{tcolorbox}

\end{frame}

\begin{frame}{This Talk}
	\begin{itemize}
		\item Survey of the public literature
		\item Synthesis of discussions with experts
		      (thx 	Lewis Tunstall, Edward Beeching, Aviral Kumar, Charlie Snell,
		      Michael Hassid, Yoav Artzi, Rishabh Agarwal, Kanishk Gandhi,
		      Wenting Zhao, Yuntian Deng, Nathan Lambert)
		\item Rumors
	\end{itemize}
	\blfootnote{}
\end{frame}

\section{The Clues}

\begin{frame}{Outline}
	\tableofcontents
\end{frame}

\begin{frame}{o1 Description}
	\begin{tcolorbox}[colback=white,colframe=black,boxrule=0.5pt]
		Our large-scale \textbf{reinforcement learning algorithm} teaches the model
		how to think productively using its \textbf{chain of thought} in a highly
		\textbf{data-efficient} training process.
	\end{tcolorbox}
\end{frame}

\begin{frame}{Implication}
	\begin{itemize}
		\item RL; Signal from verifiable problems
		\item CoT; Test-time occurs in token stream
		\item Data Efficient; Bounded set of problems
	\end{itemize}
\end{frame}

\begin{frame}{Current Assumptions}
	\begin{itemize}
		\item Single final language model
		\item Not following from expert examples
		\item Behavior is ``learned''.
	\end{itemize}
\end{frame}

\begin{frame}{Review: Chain of Thought}
	\begin{itemize}
		\item In the process of answering a question,
		      the model generates intermediate
		      steps.
		\item These steps provide an scratchpad for hard technical problems.
		\item A limited number of examples provided.
	\end{itemize}
	\blfootnote{}
\end{frame}

\begin{frame}{o1 Chain of Thought}
	\begin{tcolorbox}[colback=white,colframe=black,boxrule=0.5pt]
		o1 learns to hone its chain of thought and refine the strategies it uses.
		It learns to recognize and \textbf{correct its mistakes}.
		It learns to \textbf{break down tricky steps} into simpler ones.
		It learns to try a \textbf{different approach} when the current one isn’t working.
	\end{tcolorbox}
\end{frame}

\begin{frame}{o1 CoT: Outlining}
	\begin{tcolorbox}[colback=white,colframe=black,boxrule=0.5pt]

		Implementation Outline:

		1. Capture input string as argument.

		2. Remove any spaces (if any).

		3. Parse the input string to extract numbers into arrays.

		- Since the input is in the format '[1,2],[3,4],[5,6]', we can:

		- Remove outer brackets if necessary.

		- Split the string by '],' to get each row.

		- For each row, remove '[' and ']', then split by ',' to get elements.


		4. Build a 2D array in bash (arrays containing arrays).
	\end{tcolorbox}
\end{frame}


\begin{frame}{o1 CoT: Planning}
	\begin{tcolorbox}[colback=white,colframe=black,boxrule=0.5pt]
		First, the cipher seems connected to the plaintext.

		Given the time constraints, perhaps the easiest way is to try to see patterns.

		Option 1: Try to find mapping from letters to letters.

		Do any letters match?

		First, let's write down the ciphertext and plaintext letters on top of each other.
	\end{tcolorbox}
\end{frame}

\begin{frame}{o1 CoT: Backtracking}
	\begin{tcolorbox}[colback=white,colframe=black,boxrule=0.5pt]

		Similarly, m(x)⋅(−x 2) = (−x2n + 2 + m2n−2x2n + lower terms)m(x) * (−x 2) = (−x 2n + 2 + m 2n−2 x 2n + lower terms).

		Wait, actually, this may not help us directly without specific terms.An alternative is to consider the known polynomials.

		So m(x) = k ...
	\end{tcolorbox}
\end{frame}

\begin{frame}{o1 CoT: Self-Evaluation}

	\begin{tcolorbox}[colback=white,colframe=black,boxrule=0.5pt]
		\begin{quote}

			Let’s analyze each option.

			Option A: “because appetite regulation is a field of staggering complexity.”

			Is that a good explanation? Hmm.

			Option B: “because researchers seldom ask the right questions.”

			Does this make sense with the main clause?
		\end{quote}
	\end{tcolorbox}
\end{frame}

\begin{frame}{Summary}
	\begin{itemize}
		\item CoT provides test-time scaling
		\item CoT looks like search / planning in a classical sense
		\item RL needed to induce this behavior
	\end{itemize}
\end{frame}

\section{Technical Background}

\begin{frame}{Outline}
	\tableofcontents[hideallsubsections]
\end{frame}

\begin{frame}{Technical Background}
	\begin{itemize}
		\item Formalize sampling of latent reasoning
		\item Techniques from combinatorial sampling
		\item No learning yet.
	\end{itemize}
\end{frame}


\begin{frame}{Stepwise LLM Sampling}
	\begin{itemize}
		\item $\cx$;  problem specification
		\item $\cfz{z_{1:T}} \in {\mathcal{S}^T}$; chain of thought (CoT) steps
		\item $\cy \in \cfy{\mathcal Y}$; final answer
		      $$p(\cy | \cx) = \mathbb{E}_{\cz} p(\cy|\cx,\cz)$$
	\end{itemize}
\end{frame}

\begin{frame}{Warm-up: Ancestral Sampling}
	\begin{columns}
		\begin{column}{0.5\linewidth}
			\begin{align*}
				{\czT} & \sim p(\cdot | \cx)         \\
				{\cy}  & \sim p(\cdot | \cx, {\czT})
			\end{align*}
		\end{column}
		\begin{column}{0.5\linewidth}
			\includegraphics[width=\textwidth]{images/ancestral.png}
		\end{column}
	\end{columns}
	\vspace{1cm}
	$T$ is the amount of test-time compute
\end{frame}

\begin{frame}{Warm-up: Monte-Carlo (Self-Consistency)}
	\begin{columns}
		\begin{column}{0.5\linewidth}
			For $N$ samples,
			\begin{align*}
				{\czT}    & \sim p(\cdot | \cx)         \\
				\cfy{y^n} & \sim p(\cdot | \cx, {\czT})
			\end{align*}
			\vspace{1cm}
			Pick majority choice $\cfy{y^n}$
		\end{column}
		\begin{column}{0.5\linewidth}
			\includegraphics[width=\textwidth]{images/bwalk.png}
		\end{column}
	\end{columns}
\end{frame}

\begin{frame}{Assumption: Verifier}
	$$\text{Ver}_x : \cfy{\mathcal{Y}} \rightarrow \{0, 1\}$$

	Examples:
	\begin{itemize}
		\item Regular expression for math
		\item Unit test for code
		\item Test questions for science
	\end{itemize}
\end{frame}


\begin{frame}{Warm up: Rejection Sampling / Best-of-N}
	\begin{columns}
		\begin{column}{0.5\linewidth}
			For $n = 1$ to $N$:
			\begin{align*}
				\cz^n & \sim p(\cz | \cx)        \\
				\cy^n & \sim p(\cy | \cx, \cz^n)
			\end{align*}
			Verified set $\{\cy^n : \Ver_x(\cy^n) \}$
		\end{column}
		\begin{column}{0.5\linewidth}
			\includegraphics[width=\textwidth]{images/reject.png}
		\end{column}
	\end{columns}
	\vspace{1cm}
\end{frame}


\begin{frame}{Warm up: Monte-Carlo Roll-Outs}
	\begin{columns}
		\begin{column}{0.5\linewidth}
			Given partial CoT $\cfz{z_{1:t}}$, expected value,

			$$\mathbb{E}_{\cy\sim p(\cy| \cz, \cx), \cz_{t:T}} \Ver_x(\cy)$$

			Rollout = Monte Carlo for this expectation.
		\end{column}
		\begin{column}{0.5\linewidth}
			\includegraphics[width=\textwidth]{images/mcroll.png}
		\end{column}
	\end{columns}
\end{frame}



\begin{frame}{Goal: Learning with Latent CoTs}
	\begin{columns}
		\begin{column}{0.5\linewidth}
			Maximum likelihood;

			\begin{align*}
				\max_{\theta} & \sum \log p(\cy | \cx; \theta)  =                    \\
				              & \sum \log \mathbb{E}_{\cz} p(\cy | \cx, \cz; \theta)
			\end{align*}

			Classic combinatorial expectation
		\end{column}
		\begin{column}{0.5\linewidth}
			%\includegraphics[width=\textwidth]{images/marginal.png}
		\end{column}
	\end{columns}
\end{frame}

\section{The Suspects}

\begin{frame}{Outline}
	\tableofcontents[hideallsubsections]
\end{frame}

\begin{frame}{The Suspects}
	\begin{itemize}
		\item Guess + Check
		\item Guided Search
		\item AlphaZero
		\item Learn to Search
	\end{itemize}
\end{frame}

\subsection{Guess + Check}

\begin{frame}{Suspect 1: Guess + Check}
	\begin{columns}
		\begin{column}{0.5\linewidth}
			\begin{itemize}
				\item 1) Sample $N$ CoTs
				\item 2) Check if successful
				\item 3) Train on good ones
			\end{itemize}
		\end{column}
		\begin{column}{0.5\linewidth}
			\includegraphics[width=\textwidth]{images/reject1}
		\end{column}
	\end{columns}
\end{frame}

\begin{frame}{G+C Formalization: Rejection Sampling EM}
	$$\max_{\theta} \sum \log E_{\cz \sim p({\cz} | \cx;\theta)} p(\cy|  \cx, \cz)$$
	\begin{itemize}
		\item E-Step: For $n = 1$ to $N$:
		      \begin{align*}
			      \cz^n & \sim p(\cdot | \cx)        \\
			      \cy^n & \sim p(\cdot | \cx, \cz^n)
		      \end{align*}
		      Keep verified set $\mathcal{Z} = \{\cz^n : \Ver(\cy^n)\}$
		\item M-Step: Fit $\theta' \gets \arg\max_{\theta}
			      \sum_{{\cz} \in \mathcal{Z}} \log p({\cz} | \cx;\theta)$
	\end{itemize}
\end{frame}



\begin{frame}{G+C Variants}
	\blfootnote{\cite{Zelikman2022-id,Gulcehre2023-vk,Singh2023-eb}}
	\begin{itemize}
		\item STaR
		\item ReST
		\item ReST-EM
		\item Filtered Rejection Sampling
		\item Best-of-N Training
	\end{itemize}
\end{frame}


\begin{frame}{G+C Variants}
	\begin{itemize}
		\item Batched -> Compute trajectories first, then train with behavioral cloning
		\item Online -> Use policy gradient-like steps to update after each example
	\end{itemize}
\end{frame}


%\begin{frame}{Offline}
%	\begin{itemize}
%		\item Batch servers to sample
%		\item Check if successful
%		\item Train on good ones
%	\end{itemize}
%\end{frame}


%\begin{frame}{Online}
%	\begin{itemize}
%		\item Sample N CoTs
%		\item Check if successful
%		\item Train on good ones
%	\end{itemize}
%\end{frame}

\begin{frame}{G+C Empirical Results}
	% None of STaR, ReST, ReST-EM compare directly to self-consistency alone.
	% The closest is ReST-EM, which says that using a self-consistency on
	% the Rest-EM model gets better performance than using it on the base model (but without a figure).
	% I'm putting in figure 5 from Rest-EM for now, which shows that sampling produces
	% a correct answer more often from Rest-EM than from the base model across a range of sample
	% sizes. It doesn't show how far below these two lines self-consistency would be, but it's at least
	% evidence that Rest-EM improves on the base model. And the Pass@K performance should upper bound
	% the performance of self-consistency, since anything correct under majority voting is also correct
	% in Pass@K.
	\blfootnote{\cite{Singh2023-eb}}
	\includegraphics[width=\textwidth]{images/rest_em_figure_5.png}
\end{frame}



\begin{frame}{G+C Why might this be right?}
	\begin{columns}[T]
		\begin{column}{0.5\linewidth}
		    \textbf{Pro}
			\vspace{0.3cm}
			\begin{itemize}
				\item Extremely simple and scalable
				\item Good baseline in past work
			\end{itemize}
		\end{column}
		\begin{column}{0.5\linewidth}
		    \textbf{Con}
			\vspace{0.3cm}
			\begin{itemize}
				\item No evidence this learns to correct, plan
				\item Well-explored in literature with marginal gains
			\end{itemize}
		\end{column}
	\end{columns}
\end{frame}

\begin{frame}{More Structure?}
	\begin{itemize}
		\item Rejection sampling may be really inefficient.
		\item Particularly on hard problems, may get no signal
	\end{itemize}
\end{frame}

\subsection{Guided Search}

\begin{frame}{Suspect 2: Guided Search}
	\begin{itemize}
		\item During CoT sampling, use a heuristic to
		      improve trajectories
		\item Check if final versions are successful
		\item Train on good ones
	\end{itemize}
\end{frame}


\begin{frame}{GS: Beam Search with Guide}
	% Slightly different from token level beam search since we can't enumerate all the possible z_t like in a vocabulary,
	% so instead sample an initial k of them, score those with r and keep the top m
	%
	% A bit light on notation here (e.g. didn't define the set of z_t for each candidate prefix explicitly) to
	% avoid a lot of indices, but can add that if it needs to be more formal.
	\begin{columns}
		\begin{column}{0.5\linewidth}
			$\textcolor{c2}{r}: \cfz{\mathcal{S}^t} \rightarrow \mathbb{R}$; Guide function
			\vspace{0.3cm}

			For each step $t$
			\begin{enumerate}
				\item Sample next step,
				      $$\cfz{z_t} \sim p(\cdot | \cx, \cfz{z^i_{1:t-1}})$$
				\item Keep the top $N$ samples, ordered by $r(\cfz{z_{t}})$
			\end{enumerate}
		\end{column}
		\begin{column}{0.5\linewidth}
			\includegraphics[width=\textwidth]{images/beamguide.png}
		\end{column}
	\end{columns}
\end{frame}


\begin{frame}{What to use as Guide?}
	\begin{itemize}
		\item Monte Carlo Roll-outs
		\item Learned Value Function
		\item Interleaved Value Function
	\end{itemize}
\end{frame}


\begin{frame}{Beam Search with Roll-Outs}

	\begin{columns}
		\begin{column}{0.5\linewidth}
			For a $\cfz{z_{t}}$, sample answers $$\cfy{y^{n}} \sim p(\cdot|\cx,\cz_{1:t-1})$$
			$\textcolor{c2}{r_{MC}}(\cfz{z_{t}}) = \frac{1}{N}\sum_{i=1}^{n} \Ver(\cfy{y^{i}})$
		\end{column}
		\begin{column}{0.5\linewidth}
			\includegraphics[width=\textwidth]{images/beamroll.png}
		\end{column}
	\end{columns}
\end{frame}


\begin{frame}{Amortized Roll-Outs}
	\blfootnote{\cite{Wang2023-ur}}
	\begin{columns}
		\begin{column}{0.5\linewidth}
			\begin{itemize}
				\item Rollouts are costly, so instead learn a model $\textcolor{c2}{r_{\psi}}(\cfz{z_t})$ to approximate rollouts
				\item Use $\textcolor{c2}{r_{MC}}$ to determine labels to train $\textcolor{c2}{r_{\psi}}$
			\end{itemize}
		\end{column}
		\begin{column}{0.5\linewidth}
			\includegraphics[width=\textwidth]{images/mcroll.png}
		\end{column}
	\end{columns}
\end{frame}

\begin{frame}{Interleaved}
	\blfootnote{\cite{Wang2023-ur}}
	\begin{columns}
		\begin{column}{0.5\linewidth}
			\begin{itemize}
				\item Combine $\textcolor{c2}{r_{MC}}$ and $\textcolor{c2}{r_{\psi}}$
				\item $\textcolor{c2}{r_{Inter}}(\cfz{z_t}) = (1-\alpha)\textcolor{c2}{r_{MC}}(\cfz{z_t}) + \alpha\textcolor{c2}{r_{\psi}}(\cfz{z_t})$
			\end{itemize}
		\end{column}
		\begin{column}{0.5\linewidth}

		\end{column}
	\end{columns}
\end{frame}


\begin{frame}{What about test time?}
	\begin{itemize}
		\item Learned rewards can improve test-time without verifier.
		\item
	\end{itemize}
\end{frame}

\begin{frame}{Test-time Guides Outperform Self-consistency}
% I think this is a nice empirical figure to show that learned rewards improve the test-time
% performance over self-consistency.
\includegraphics[width=\textwidth]{images/math_shepherd_figure_3.png}
\end{frame}


\begin{frame}{Terminology}
	\begin{itemize}
		\item Value
		\item PRM
		\item PAV
		\item Math Shepard.
		\item snell.
	\end{itemize}
	\blfootnote{\cite{Uesato2022-aw,Setlur2024-ax,Wang2023-ur,Lightman2023-cr,Snell2024-dx}}
\end{frame}


\begin{frame}{Why might this be right?}
	\begin{itemize}
		\item OpenAI is exploring
		\item Makes RS more efficient.
		\item Learned rewards are effective
	\end{itemize}
	\begin{itemize}
		\item Assumption: o1 is a single test-time model
		      (although could train or distill-in)
		\item Not clear if it learns planning.
	\end{itemize}
\end{frame}


\begin{frame}{More Structure}
	\begin{itemize}
		\item Improving search seems critical.
	\end{itemize}
\end{frame}

\subsection{AlphaZero}

\begin{frame}{Reminder: AlphaZero}
	\centering
	\includegraphics[height=0.8\textheight]{images/alphazero_figure_one.png}
\end{frame}

\begin{frame}{Suspect 3: AlphaZero}
	\begin{itemize}
		\item Self-play using guided-search with exploration
		\item Label final outcomes of self-play games
		\item Train guide and generator
	\end{itemize}
\end{frame}

\begin{frame}{Formalized: Expert Iteration}
	% VSTaR is almost the LM equivalent of AlphaZero in the framing,
	% except that AlphaZero learns a PRM (value function) and V-STaR learns an ORM.
	% Plus AlphaZero uses its PRM during search, which V-STaR can't do.
	%
	% I wrote this with the reward model involved, but technically expert iteration doesn't
	% require that. At that point I think it reduces to Rejection Sampling EM though.
	\begin{itemize}
		\item Iterative algorithm combining learned model + expert search with a verifier.
		\item Generate samples using $p(\cy,\cz|\cx)$, reward model $r(\cz_t)$, and search algorithm (e.g. beam search)
		\item Label samples using $Ver_x(\cy)$
		\item Train $p(\cy,\cz|\cx)$, $r(\cz_t)$ on the labeled samples, and repeat
	\end{itemize}
	\blfootnote{\cite{Anthony2017-dm}}

\end{frame}

\begin{frame}{MCTS exploration}
	% Not sure if there's a way to formalize this for language models, since
	% we're unlikely to get the same z twice (i.e. end up in the same state/action pair).
	% That means the state visit counts in the usual UCB formulation don't work.
	% The exploration in previous methods here has come from sampling or
	% maintaining multiple candidates, rather than tracking UCB statistics.

\end{frame}


\begin{frame}{UCB for Language}
	\begin{itemize}
		\item Selection: Walk down tree to leaf $\cfz{z_{t-1}}$
		\item Expand: Sample $K$ next steps $\cfz{z^i_t}$, pick one at random
		\item Rollouts: Sample $\cfz{z_{t+1}} \ldots \cfz{z_T}$
		\item Backprop: Update nodes counts $z_{1:t}$ based on results
	\end{itemize}
\end{frame}


\begin{frame}{Compared with Search}
	\begin{columns}[T]
		\begin{column}{0.48\textwidth}
		      \textbf{Pro}
			\vspace{0.3cm}
			\begin{itemize}
				\item System builds in exploration
				\item Scales to more train-time search
			\end{itemize}
		\end{column}
		\begin{column}{0.48\textwidth}
		      \textbf{Con}
			\vspace{0.3cm}
			\begin{itemize}
				\item Costly to maintain open states
				\item More complex algorithmically
			\end{itemize}
		\end{column}
	\end{columns}
\end{frame}


\begin{frame}{Empirical Results}
	% figure from appendix of the VSTaR paper
	% VSTaR is sort of a weird variation of expert iteration. The learned model is
	% both the generator and the verifier, but only the generator influences the
	% expert search (since it determines what the samples are at the next iteration that the verifier labels).
	% I think it still falls within expert iteration, though, just with an expert policy
	% that's independent of the reward model.
	\includegraphics[width=\textwidth]{images/vstar_figure_8.png}
	\blfootnote{\cite{hosseini2024vstar}}
\end{frame}


\begin{frame}{Why might this be right?}
	\begin{itemize}
		\item Major demonstrated RL result
		\item
	\end{itemize}
	\begin{itemize}
		\item
		\item
	\end{itemize}
\end{frame}


\begin{frame}{More Structure}
	\begin{itemize}
		\item Can we force the model to search?
	\end{itemize}
\end{frame}

\subsection{Learning to Correct}

\begin{frame}{Suspect 4: Learning to Correct}
	\begin{itemize}
		\item Sample $N$ Successful CoTs
		\item Edit to inject incorrect expansions before
		      correct ones.
		\item Train on correcting trajectories
	\end{itemize}
\end{frame}


\begin{frame}{Self-Correction}
	\begin{itemize}
		\item Argument: Training on $\cx, \cfz{z^*_1}, \cy$ is too easy.
		\item Train instead on $\cx, \cfz{z'}, \cfz{z^*_1}, \cy$
		\item Model should learn to self-correct
	\end{itemize}
	\blfootnote{\cite{Gandhi2024-vs}}
\end{frame}

\begin{frame}{Score}
	\begin{itemize}
		\item Positive rewards
	\end{itemize}
\end{frame}


\begin{frame}{Challenge: Collapse}
	\begin{itemize}
		\item Model may learn to just ignore negative
		\item
		\item
	\end{itemize}
\end{frame}


\begin{frame}{Generalized: Stream of Search}
	\begin{itemize}
		\item Find $\cfz{z^*_{1:T}}$ as optimal length CoT
		\item Find $\cfz{z'_{1:T'}}$ with $T' > T$ through backtracking tree search
		\item Train model on $\cfz{z'_{1:T'}}$
	\end{itemize}
	\blfootnote{\cite{Gandhi2024-vs}}
\end{frame}

\begin{frame}{From Tree to Stream}
	\begin{itemize}
	   \item
	\end{itemize}
	\blfootnote{\cite{Gandhi2024-vs}}
\end{frame}



\begin{frame}{Empirical Results}
\includegraphics[width=\textwidth]{images/score_figure_1.png}
\end{frame}
\begin{frame}{Empirical Results}
% This one is more detailed than figure 1, but we can also cut it out if
% it makes more sense to just have the one figure with MATH performance and compute scaling
\includegraphics[width=\textwidth]{images/score_table_2.png}
\end{frame}

\begin{frame}{Why might this be right?}
	\begin{itemize}
		\item
		\item
	\end{itemize}
	\begin{itemize}
		\item
		\item
	\end{itemize}
\end{frame}

\begin{frame}{Less Structure?}
	\begin{itemize}
		\item Maybe this is all too much...
		\item Could this be done without a verifier?
	\end{itemize}
\end{frame}

\begin{frame}{Outline}
	\tableofcontents[]
\end{frame}

\section{What do we do now?}

\begin{frame}{Replication}

\end{frame}


\begin{frame}{Does it need to be the same?}

\end{frame}

\begin{frame}{}

\end{frame}

\begin{frame}[allowframebreaks]{Reference}
	\bibliographystyle{apalike}
	\bibliography{../o1.bib,../o1.extra.bib}
\end{frame}

\end{document}
